# Papers-on-Protein

## Protein Generation
 ### Function to Sequence
**ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models**   
Lee, Youhan, and Hasun Yu  
*ICLR, 2023*  
[[Paper](https://openreview.net/forum?id=9XAZBUfnefS)]

**Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design**  
Ilia Igashov, Hannes Stärk, Clément Vignac, Arne Schneuing, Victor Garcia Satorras, Pascal Frossard, Max Welling, Michael Bronstein and Bruno Correia  
*Nature Machine Intelligence*  
[[Paper](https://www.nature.com/articles/s42256-024-00815-9)] [[Code](https://github.com/igashov/DiffLinker)]  

**PiFold: Toward effective and efficient protein inverse folding**  
Zhangyang Gao, Cheng Tan, and Stan Z. Li  
*ICLR, 2023*  
[[Paper](https://arxiv.org/abs/2209.12643)] [[Code](https://github.com/A4Bio/PiFold)]  

**Reprogramming Pretrained Language Models for Antibody Sequence Infilling**  
Igor Melnyk, Vijil Chenthamarakshan, Pin-Yu Chen, Payel Das, Amit Dhurandhar, Inkit Padhi, and Devleena Das  
*arXiv Preprint*  
[[Paper](https://arxiv.org/pdf/2210.07144v2)]

**Alphafold Distillation For Improved Inverse Protein Folding**  
Igor Melnyk, Aurelie Lozano, Payel Das, and Vijil Chenthamarakshan  
*arXiv Preprint*  
[[Paper](https://arxiv.org/abs/2210.03488)]

**Protein Design And Variant Prediction Using Autoregressive Generative Models**  
Jung-Eun Shin, Adam Riesselman, Kollasch, Conor McMahon, Elana Simon, Chris Sander, Aashish Manglik, Andrew Kruse, and Debora Marks  
*Nature Communications, 2021*  
[[Paper](https://www.nature.com/articles/s41467-021-22732-w)]

**Protein Sequence Design with a Learned Potential**  
Namrata Anand, Raphael R. Eguchi, Alexander Derry, Russ B. Altman, Po-Ssu Huang.  
*Preprint*  
[[Paper](https://doi.org/10.1101/2020.01.06.895466)]  

**Regression Transformer Enables Concurrent Sequence Regression And Generation For Molecular Language Modelling**  
Jannis Born, and Matteo Manica  
*Nature Machine Intelligence*  
[[Paper](https://www.nature.com/articles/s42256-023-00639-z)] 

**Towards Controllable Protein Design With Conditional Transformers**  
Noelia Ferruz, and Birte Höcker  
*Preprint*  
[[Paper](https://arxiv.org/pdf/2201.07338)]

**Robust Deep Learning Based Protein Sequence Design Using ProteinMPNN**  
J. Dauparas, I. Anishchenko, N. Bennett, H. Bai, R. J. Ragotte, L. F. Milles, B. I. M. Wicky, A. Courbet, R. J. de Haas, N. Bethel, P. J. Y. Leung, T. F. Huddy, S. Pellock, D. Tischer, F. Chan, B. Koepnick, H. Nguyen, A. Kang, B. Sankaran, A. K. Bera, N. P. King, and D. Baker  
*Science, 2022*  
[[Paper](https://www.science.org/doi/10.1126/science.add2187)] 

### Function to Structure

**Protein Sequence and Structure Co-Design with Equivariant Translation**   
Chence Shi, Chuanrui Wang, Jiarui Lu, Bozitao Zhong, and Jian Tang  
*ICLR, 2023*  
[[Paper](https://arxiv.org/abs/2210.08761)] [[Code](https://github.com/shichence/ProtSeed)]  

**Protein Sequence and Structure Co-Design with Equivariant Translation**   
Nathan C. Frey, Daniel Berenberg, Karina Zadorozhny, Joseph Kleinhenz, Julien Lafrance-Vanasse, Isidro Hotzel, Yan Wu, Stephen Ra, Richard Bonneau, Kyunghyun Cho, Andreas Loukas, Vladimir Gligorijevic, and Saeed Saremi  
*ICLR, 2024*  
[[Paper](https://arxiv.org/pdf/2306.12360)]

**De novo design of protein structure and function with RFdiffusion**   
Joseph L. Watson, David Juergens, Nathaniel R. Bennett, Brian L. Trippe, Jason Yim, Helen E. Eisenach, Woody Ahern, Andrew J. Borst, Robert J. Ragotte, Lukas F. Milles, Basile I. M. Wicky, Nikita Hanikel, Samuel J. Pellock, Alexis Courbet, William Sheffler, Jue Wang, Preetham Venkatesh, Isaac Sappington, Susana Vázquez Torres, Anna Lauko, Valentin De Bortoli, Emile Mathieu, Sergey Ovchinnikov, Regina Barzilay, Tommi S. Jaakkola, Frank DiMaio, Minkyung Baek and David Baker  
*Nature, 2023*  
[[Paper](https://www.nature.com/articles/s41586-023-06415-8)] [[Code](https://github.com/RosettaCommons/RFdiffusion)]  

## Protein Representation Learning
**Protein Representation Learning via Knowledge Enhanced Primary Structure Modeling**  
Hong-Yu Zhou, Yunxiang Fu, Zhicheng Zhang, Cheng Bian, and Yizhou Yu  
*ICLR, 2023*  
[[Paper](https://arxiv.org/abs/2301.13154)]  

**Protein Representation Learning By Geometric Structure Pretraining**  
Jiaxin Xie, Hao Ouyang, Jingtan Piao, Chenyang Lei, Qifeng Chen  
*ICLR, 2023*  
[[Paper](https://arxiv.org/abs/2203.06125)]  

**Multi-Level Protein Structure Pre-Training With Prompt Learning**  
Titas Anciukevicius, Zexiang Xu, Matthew Fisher, Paul Henderson, Hakan Bilen, Niloy J. Mitra, Paul Guerrero  
*ICLR, 2023*  
[[Paper](https://openreview.net/forum?id=XGagtiJ8XC)]


## Benchmark
**On Pre-Trained Language Models For Antibody**  
Danqing Wang, Fei Ye, and Hao Zhou  
*arXiv Preprint*  
[[Paper](https://arxiv.org/abs/2301.12112)]  

**PEER: A Comprehensive and Multi-Task Benchmark for Protein Sequence Understanding**  
Minghao Xu, Zuobai Zhang, Jiarui Lu, Zhaocheng Zhu, Yangtian Zhang, Chang Ma, Runcheng Liu, and Jian Tang  
*NeurIPS, 2022*  
[[Paper](https://arxiv.org/abs/2206.02096)]  [[Project Page](https://torchprotein.ai/benchmark)]   


